{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook is for the Models of our Project.\n",
    "\n",
    "Models include:\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "- KNN\n",
    "- Neural Network\n",
    "\n",
    "Below you can find the Pre-processing, Training, and Testing for Each model\n",
    "\n",
    "At the end we will conclude with a comparison between each model and discuss results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.decomposition import PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collection\n",
    "data = pd.read_csv('credit_card_fraud.csv', parse_dates=['trans_date_trans_time',])\n",
    "\n",
    "X = data.drop(['is_fraud'], axis=1)\n",
    "Y = data['is_fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to calculate the distance between to longitude and latitude points.\n",
    "# Since we have both the customer (lat, long) at time of purchase and the merchant's (lat,long) we can compute the distance between the two\n",
    "# this could lead us seeing if the is any correlation between how far a purchase is and if it is fraud or not\n",
    "def distance(lat1, lon1, lat2, lon2):\n",
    "    # radius of the Earth in km\n",
    "    R = 6371.0\n",
    "\n",
    "    # convert degrees to radians\n",
    "    lat1 = math.radians(lat1)\n",
    "    lon1 = math.radians(lon1)\n",
    "    lat2 = math.radians(lat2)\n",
    "    lon2 = math.radians(lon2)\n",
    "\n",
    "    # compute the differences between the two points\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    # compute the Haversine formula\n",
    "    a = math.sin(dlat / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    dist = R * c\n",
    "\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing --------------------------------------------------------\n",
    "\n",
    "# changing data types\n",
    "X['dob'] = pd.to_datetime(X['dob'])\n",
    "\n",
    "# creating columns out of our original Dataset --------------------------\n",
    "\n",
    "X['hour_of_transaction'] = X.trans_date_trans_time.dt.hour # hour of transaction\n",
    "X['month_of_transaction'] = X.trans_date_trans_time.dt.month # month of transaction\n",
    "X['dow_of_transaction'] = X.trans_date_trans_time.dt.day_name() # day of week of transaction\n",
    "X['cust_age'] = (X['trans_date_trans_time'] - X['dob']).astype('timedelta64[Y]') # age of person during transaction\n",
    "X['distance_of_transaction'] = X.apply(lambda row: distance(row['lat'], row['long'], row['merch_lat'], row['merch_long']), axis=1) # distance of transaction\n",
    "\n",
    "# encoding: 0 = normal time, 1 = odd time\n",
    "X['Normal_transaction_time'] = 0\n",
    "X.loc[X.hour_of_transaction < 5,'Normal_transaction_time'] = 1\n",
    "X.loc[X.hour_of_transaction > 21,'Normal_transaction_time'] = 1\n",
    "\n",
    "# one-hot encoding the categorical features\n",
    "encoder = OneHotEncoder()\n",
    "dow_encoded = encoder.fit_transform(X[['dow_of_transaction']])\n",
    "dow_encoded_df = pd.DataFrame(dow_encoded.toarray(), columns=encoder.categories_[0])\n",
    "X = pd.concat([X, dow_encoded_df], axis=1)\n",
    "\n",
    "state_encoded = encoder.fit_transform(X[['state']])\n",
    "state_encoded_df = pd.DataFrame(state_encoded.toarray(), columns=encoder.categories_[0])\n",
    "X = pd.concat([X,state_encoded_df], axis=1)\n",
    "\n",
    "merch_encoded = encoder.fit_transform(X[['merchant']])\n",
    "merch_encoded_df = pd.DataFrame(merch_encoded.toarray(), columns=encoder.categories_[0])\n",
    "X = pd.concat([X, merch_encoded_df], axis=1)\n",
    "\n",
    "cat_encoded = encoder.fit_transform(X[['category']])\n",
    "cat_encoded_df = pd.DataFrame(cat_encoded.toarray(), columns=encoder.categories_[0])\n",
    "X = pd.concat([X, cat_encoded_df], axis=1)\n",
    "\n",
    "city_encoded = encoder.fit_transform(X[['city']])\n",
    "city_encoded_df = pd.DataFrame(city_encoded.toarray(), columns=encoder.categories_[0])\n",
    "X = pd.concat([X, city_encoded_df], axis=1)\n",
    "\n",
    "\n",
    "# Normalizing the features with varying ranges of numbers ------------------------------------------------------------\n",
    "\n",
    "# min-max normalization since no real outliers for these features\n",
    "X['cust_age'] = (X['cust_age'] - X['cust_age'].min()) / (X['cust_age'].max() - X['cust_age'].min())\n",
    "\n",
    "# z-score normalization for values that are wide-spread such as amt and city population\n",
    "X['amt'] = (X['amt'] - X['amt'].mean()) / X['amt'].std() \n",
    "X['city_pop'] = (X['city_pop'] - X['city_pop'].mean()) / X['city_pop'].std() \n",
    "\n",
    "# getting rid of unnecessary columns\n",
    "X.drop(['trans_num', 'job','trans_date_trans_time', 'state', 'city', 'merchant', 'category', 'dow_of_transaction', 'dob'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amt</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>hour_of_transaction</th>\n",
       "      <th>month_of_transaction</th>\n",
       "      <th>cust_age</th>\n",
       "      <th>distance_of_transaction</th>\n",
       "      <th>...</th>\n",
       "      <th>Wales</th>\n",
       "      <th>Wappapello</th>\n",
       "      <th>Weeping Water</th>\n",
       "      <th>Wendel</th>\n",
       "      <th>Westerville</th>\n",
       "      <th>Westfir</th>\n",
       "      <th>Wheaton</th>\n",
       "      <th>Williamsburg</th>\n",
       "      <th>Woods Cross</th>\n",
       "      <th>Yellowstone National Park</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.226701</td>\n",
       "      <td>48.8878</td>\n",
       "      <td>-118.2105</td>\n",
       "      <td>-0.365123</td>\n",
       "      <td>49.159047</td>\n",
       "      <td>-118.186462</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.302632</td>\n",
       "      <td>30.212176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.924891</td>\n",
       "      <td>42.1808</td>\n",
       "      <td>-112.2620</td>\n",
       "      <td>-0.351455</td>\n",
       "      <td>43.150704</td>\n",
       "      <td>-112.154481</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.513158</td>\n",
       "      <td>108.206083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.159035</td>\n",
       "      <td>41.6125</td>\n",
       "      <td>-122.5258</td>\n",
       "      <td>-0.363621</td>\n",
       "      <td>41.657520</td>\n",
       "      <td>-122.230347</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>25.059079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.388482</td>\n",
       "      <td>32.9396</td>\n",
       "      <td>-105.8189</td>\n",
       "      <td>-0.362563</td>\n",
       "      <td>32.863258</td>\n",
       "      <td>-106.520205</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>66.021685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.394173</td>\n",
       "      <td>43.0172</td>\n",
       "      <td>-111.0292</td>\n",
       "      <td>-0.364024</td>\n",
       "      <td>43.753735</td>\n",
       "      <td>-111.454923</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>88.830984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 914 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        amt      lat      long  city_pop  merch_lat  merch_long  \\\n",
       "0  0.226701  48.8878 -118.2105 -0.365123  49.159047 -118.186462   \n",
       "1  0.924891  42.1808 -112.2620 -0.351455  43.150704 -112.154481   \n",
       "2  0.159035  41.6125 -122.5258 -0.363621  41.657520 -122.230347   \n",
       "3 -0.388482  32.9396 -105.8189 -0.362563  32.863258 -106.520205   \n",
       "4 -0.394173  43.0172 -111.0292 -0.364024  43.753735 -111.454923   \n",
       "\n",
       "   hour_of_transaction  month_of_transaction  cust_age  \\\n",
       "0                    0                     1  0.302632   \n",
       "1                    0                     1  0.513158   \n",
       "2                    0                     1  0.736842   \n",
       "3                    0                     1  0.447368   \n",
       "4                    0                     1  0.447368   \n",
       "\n",
       "   distance_of_transaction  ...  Wales  Wappapello  Weeping Water  Wendel  \\\n",
       "0                30.212176  ...    0.0         0.0            0.0     0.0   \n",
       "1               108.206083  ...    0.0         0.0            0.0     0.0   \n",
       "2                25.059079  ...    0.0         0.0            0.0     0.0   \n",
       "3                66.021685  ...    0.0         0.0            0.0     0.0   \n",
       "4                88.830984  ...    0.0         0.0            0.0     0.0   \n",
       "\n",
       "   Westerville  Westfir  Wheaton  Williamsburg  Woods Cross  \\\n",
       "0          0.0      0.0      0.0           0.0          0.0   \n",
       "1          0.0      0.0      0.0           0.0          0.0   \n",
       "2          0.0      0.0      0.0           0.0          0.0   \n",
       "3          0.0      0.0      0.0           0.0          0.0   \n",
       "4          0.0      0.0      0.0           0.0          0.0   \n",
       "\n",
       "   Yellowstone National Park  \n",
       "0                        0.0  \n",
       "1                        0.0  \n",
       "2                        0.0  \n",
       "3                        0.0  \n",
       "4                        0.0  \n",
       "\n",
       "[5 rows x 914 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.762639</td>\n",
       "      <td>13.488977</td>\n",
       "      <td>11.531076</td>\n",
       "      <td>6.148449</td>\n",
       "      <td>0.196133</td>\n",
       "      <td>-0.043365</td>\n",
       "      <td>-0.098173</td>\n",
       "      <td>-0.496094</td>\n",
       "      <td>-0.391983</td>\n",
       "      <td>-0.204738</td>\n",
       "      <td>-0.267780</td>\n",
       "      <td>0.220493</td>\n",
       "      <td>-0.686378</td>\n",
       "      <td>-0.175062</td>\n",
       "      <td>-0.324896</td>\n",
       "      <td>-0.028146</td>\n",
       "      <td>-0.378488</td>\n",
       "      <td>-0.572667</td>\n",
       "      <td>-0.153772</td>\n",
       "      <td>-0.015224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.663536</td>\n",
       "      <td>5.169252</td>\n",
       "      <td>12.366131</td>\n",
       "      <td>6.167659</td>\n",
       "      <td>0.821876</td>\n",
       "      <td>0.306590</td>\n",
       "      <td>-0.096498</td>\n",
       "      <td>-0.475124</td>\n",
       "      <td>-0.161804</td>\n",
       "      <td>-0.580113</td>\n",
       "      <td>-0.558632</td>\n",
       "      <td>0.329400</td>\n",
       "      <td>-0.664159</td>\n",
       "      <td>0.043374</td>\n",
       "      <td>-0.310994</td>\n",
       "      <td>-0.040888</td>\n",
       "      <td>0.049311</td>\n",
       "      <td>-0.045441</td>\n",
       "      <td>-0.059226</td>\n",
       "      <td>-0.054507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.908968</td>\n",
       "      <td>2.655734</td>\n",
       "      <td>12.472429</td>\n",
       "      <td>6.173480</td>\n",
       "      <td>0.073120</td>\n",
       "      <td>0.358790</td>\n",
       "      <td>-0.082031</td>\n",
       "      <td>-0.519137</td>\n",
       "      <td>-0.404864</td>\n",
       "      <td>-0.431200</td>\n",
       "      <td>-0.132352</td>\n",
       "      <td>-0.563000</td>\n",
       "      <td>-0.750026</td>\n",
       "      <td>0.057217</td>\n",
       "      <td>-0.338387</td>\n",
       "      <td>-0.033824</td>\n",
       "      <td>-0.283833</td>\n",
       "      <td>-0.463733</td>\n",
       "      <td>-0.426065</td>\n",
       "      <td>0.066462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6.851540</td>\n",
       "      <td>-7.925427</td>\n",
       "      <td>13.650886</td>\n",
       "      <td>6.198347</td>\n",
       "      <td>-0.537756</td>\n",
       "      <td>0.618512</td>\n",
       "      <td>-0.111379</td>\n",
       "      <td>-0.480808</td>\n",
       "      <td>-0.425854</td>\n",
       "      <td>0.343206</td>\n",
       "      <td>-0.490844</td>\n",
       "      <td>0.614755</td>\n",
       "      <td>-0.655615</td>\n",
       "      <td>0.127032</td>\n",
       "      <td>-0.309509</td>\n",
       "      <td>-0.056618</td>\n",
       "      <td>-0.081410</td>\n",
       "      <td>-0.203623</td>\n",
       "      <td>0.230281</td>\n",
       "      <td>-0.300932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.372367</td>\n",
       "      <td>6.281370</td>\n",
       "      <td>12.278311</td>\n",
       "      <td>6.164148</td>\n",
       "      <td>-0.480372</td>\n",
       "      <td>0.107973</td>\n",
       "      <td>-0.103271</td>\n",
       "      <td>-0.486222</td>\n",
       "      <td>-0.209540</td>\n",
       "      <td>-0.189112</td>\n",
       "      <td>-0.710503</td>\n",
       "      <td>0.351519</td>\n",
       "      <td>-0.668539</td>\n",
       "      <td>0.108710</td>\n",
       "      <td>-0.302570</td>\n",
       "      <td>-0.042627</td>\n",
       "      <td>-0.283745</td>\n",
       "      <td>-0.417400</td>\n",
       "      <td>0.506267</td>\n",
       "      <td>0.194498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1          2         3         4         5         6   \\\n",
       "0  11.762639  13.488977  11.531076  6.148449  0.196133 -0.043365 -0.098173   \n",
       "1   2.663536   5.169252  12.366131  6.167659  0.821876  0.306590 -0.096498   \n",
       "2  16.908968   2.655734  12.472429  6.173480  0.073120  0.358790 -0.082031   \n",
       "3  -6.851540  -7.925427  13.650886  6.198347 -0.537756  0.618512 -0.111379   \n",
       "4   1.372367   6.281370  12.278311  6.164148 -0.480372  0.107973 -0.103271   \n",
       "\n",
       "         7         8         9         10        11        12        13  \\\n",
       "0 -0.496094 -0.391983 -0.204738 -0.267780  0.220493 -0.686378 -0.175062   \n",
       "1 -0.475124 -0.161804 -0.580113 -0.558632  0.329400 -0.664159  0.043374   \n",
       "2 -0.519137 -0.404864 -0.431200 -0.132352 -0.563000 -0.750026  0.057217   \n",
       "3 -0.480808 -0.425854  0.343206 -0.490844  0.614755 -0.655615  0.127032   \n",
       "4 -0.486222 -0.209540 -0.189112 -0.710503  0.351519 -0.668539  0.108710   \n",
       "\n",
       "         14        15        16        17        18        19  \n",
       "0 -0.324896 -0.028146 -0.378488 -0.572667 -0.153772 -0.015224  \n",
       "1 -0.310994 -0.040888  0.049311 -0.045441 -0.059226 -0.054507  \n",
       "2 -0.338387 -0.033824 -0.283833 -0.463733 -0.426065  0.066462  \n",
       "3 -0.309509 -0.056618 -0.081410 -0.203623  0.230281 -0.300932  \n",
       "4 -0.302570 -0.042627 -0.283745 -0.417400  0.506267  0.194498  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=20)\n",
    "pca.fit(X)\n",
    "X_pca = pca.transform(X)\n",
    "X_pca = pd.DataFrame(X_pca)\n",
    "X_pca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this data set is heavely skewed in Non-Fraudulent transactions favor, we have done some research in how to address this.\n",
    "We concluded that we can take the approach of doing under-sampling, over-sampling, and combining both.\n",
    "\n",
    "Under-sampling: The number of samples taken from majority class (Not Fraud) will be equal to total number of samples of minority class (Fraud)\n",
    "Over-sampling: Selecting random samples from the minority class (Fraud) and adding to the training data copies of the sample\n",
    "\n",
    "\n",
    "Logistic Regression Model - Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape   :  (2851, 914)\n",
      "Training Labels Shape :  (2851,)\n",
      "Testing Data Shape    :  (713, 914)\n",
      "Testing Labels Shape  :  (713,)\n",
      "\n",
      "Logistic Regression Results with Under-Sampling:\n",
      "\n",
      "Training Accuracy :  0.890915468256752\n",
      "Testing  Accuracy :  0.9004207573632539\n",
      "Training Set f1 score :  0.8936752136752136\n",
      "Testing  Set f1 score :  0.8957415565345079\n",
      "\n",
      "Test set precision :  0.8843031123139378\n",
      "Test set recall    :  0.9104477611940298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cs484/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "under_sample = RandomUnderSampler()\n",
    "X_under, Y_under = under_sample.fit_resample(X,Y) # data set used for all under sampled models\n",
    "\n",
    "X_train_u, X_test_u, Y_train_u, Y_test_u = train_test_split(X_under, Y_under, test_size = 0.2, random_state=42)\n",
    "\n",
    "print('Training Data Shape   : ', X_train_u.shape)\n",
    "print('Training Labels Shape : ', Y_train_u.shape)\n",
    "print('Testing Data Shape    : ', X_test_u.shape)\n",
    "print('Testing Labels Shape  : ', Y_test_u.shape)\n",
    "print()\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train_u,Y_train_u)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "pred_train_lr = lr_model.predict(X_train_u)\n",
    "pred_test_lr  = lr_model.predict(X_test_u)\n",
    "\n",
    "print('Logistic Regression Results with Under-Sampling:')\n",
    "print()\n",
    "print('Training Accuracy : ', accuracy_score(Y_train_u, pred_train_lr))\n",
    "print('Testing  Accuracy : ', accuracy_score(Y_test_u, pred_test_lr))\n",
    "\n",
    "# Checking f1 score, precision and recall\n",
    "print('Training Set f1 score : ', f1_score(Y_train_u, pred_train_lr))\n",
    "print('Testing  Set f1 score : ', f1_score(Y_test_u, pred_test_lr))\n",
    "print()\n",
    "print('Test set precision : ', precision_score(Y_train_u, pred_train_lr))\n",
    "print('Test set recall    : ', recall_score(Y_test_u, pred_test_lr))\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Model - Under Sampling\n",
    "\n",
    "Hyperparameters include:\n",
    "n_estimators: Determines the number of decision tress that are \"grown\" in random forest\n",
    "max_depth: the maximum depth for each decision tree\n",
    "random_state: helps randomize the data to generate diverse decision trees and will help in comparing later since each model has same random_state\n",
    "\n",
    "Hyperparameters tested:\n",
    "\n",
    "n_estimators=100, max_depth=10, random_state=42\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Results with Under-Sampling:\n",
      "\n",
      "Training Set Accuracy :  1.0\n",
      "Testing Set Accuracy  :  0.9565217391304348\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=200, max_depth=200, random_state=42)\n",
    "rf_classifier.fit(X_train_u, Y_train_u)\n",
    "\n",
    "pred_train_rf = rf_classifier.predict(X_train_u)\n",
    "pred_test_rf = rf_classifier.predict(X_test_u)\n",
    "\n",
    "print('Random Forest Classifier Results with Under-Sampling:')\n",
    "print()\n",
    "\n",
    "print('Training Set Accuracy : ', accuracy_score(Y_train_u, pred_train_rf))\n",
    "print('Testing Set Accuracy  : ', accuracy_score(Y_test_u, pred_test_rf))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network (MLP) Classifier Results with Under-Sampling:\n",
      "\n",
      "Training Set Accuracy :  0.9600140301648544\n",
      "Testing Set Accuracy  :  0.85273492286115\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "nn_classifier = MLPClassifier(hidden_layer_sizes=(914,500,250,100,50,1), activation='relu', random_state=42)\n",
    "nn_classifier.fit(X_train_u, Y_train_u)\n",
    "\n",
    "pred_train_nn = nn_classifier.predict(X_train_u)\n",
    "pred_test_nn = nn_classifier.predict(X_test_u)\n",
    "\n",
    "print('Neural Network (MLP) Classifier Results with Under-Sampling:')\n",
    "print()\n",
    "\n",
    "print('Training Set Accuracy : ', accuracy_score(Y_train_u, pred_train_nn))\n",
    "print('Testing Set Accuracy  : ', accuracy_score(Y_test_u, pred_test_nn))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape   :  (540520, 913)\n",
      "Training Labels Shape :  (540520,)\n",
      "Testing Data Shape    :  (135130, 913)\n",
      "Testing Labels Shape  :  (135130,)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cs484/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results with Under-Sampling:\n",
      "\n",
      "Training Accuracy :  0.8968770813290905\n",
      "Testing  Accuracy :  0.8968992821727225\n",
      "Training Set f1 score :  0.899475556004415\n",
      "Testing  Set f1 score :  0.8997467042772438\n",
      "\n",
      "Test set precision :  0.8770777206446122\n",
      "Test set recall    :  0.9240160215196795\n"
     ]
    }
   ],
   "source": [
    "over_sample = RandomOverSampler()\n",
    "X_over, Y_over = over_sample.fit_resample(X,Y) # data set used for all over sampled models\n",
    "\n",
    "\n",
    "X_train_o, X_test_o, Y_train_o, Y_test_o = train_test_split(X_over, Y_over, test_size = 0.2, random_state=42)\n",
    "\n",
    "print('Training Data Shape   : ', X_train_o.shape)\n",
    "print('Training Labels Shape : ', Y_train_o.shape)\n",
    "print('Testing Data Shape    : ', X_test_o.shape)\n",
    "print('Testing Labels Shape  : ', Y_test_o.shape)\n",
    "print()\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model_over = LogisticRegression()\n",
    "lr_model_over.fit(X_train_o,Y_train_o)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "pred_train_lr2 = lr_model_over.predict(X_train_o)\n",
    "pred_test_lr2  = lr_model_over.predict(X_test_o)\n",
    "\n",
    "print('Logistic Regression Results with Under-Sampling:')\n",
    "print()\n",
    "print('Training Accuracy : ', accuracy_score(Y_train_o, pred_train_lr2))\n",
    "print('Testing  Accuracy : ', accuracy_score(Y_test_o, pred_test_lr2))\n",
    "\n",
    "# Checking f1 score, precision and recall\n",
    "print('Training Set f1 score : ', f1_score(Y_train_o, pred_train_lr2))\n",
    "print('Testing  Set f1 score : ', f1_score(Y_test_o, pred_test_lr2))\n",
    "print()\n",
    "print('Test set precision : ', precision_score(Y_train_o, pred_train_lr2))\n",
    "print('Test set recall    : ', recall_score(Y_test_o, pred_test_lr2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Results with Under-Sampling:\n",
      "\n",
      "Training Set Accuracy :  0.968252793606157\n",
      "Testing Set Accuracy  :  0.9680011840449937\n"
     ]
    }
   ],
   "source": [
    "rf_classifier_o = RandomForestClassifier(n_estimators=200, max_depth=200, random_state=42)\n",
    "rf_classifier_o.fit(X_train_o, Y_train_o)\n",
    "\n",
    "pred_train_rf2 = rf_classifier.predict(X_train_o)\n",
    "pred_test_rf2 = rf_classifier.predict(X_test_o)\n",
    "\n",
    "print('Random Forest Classifier Results with Under-Sampling:')\n",
    "print()\n",
    "\n",
    "print('Training Set Accuracy : ', accuracy_score(Y_train_o, pred_train_rf2))\n",
    "print('Testing Set Accuracy  : ', accuracy_score(Y_test_o, pred_test_rf2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs484",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
